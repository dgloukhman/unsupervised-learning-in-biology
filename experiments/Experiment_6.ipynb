{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e6394d",
   "metadata": {},
   "source": [
    "# Learning Encodes Alignment within a Protein Family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e91d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to import modules from helpers\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "# Gehe einen Ordner nach oben\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f5a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "from helpers import helper\n",
    "import time\n",
    "import io\n",
    "import urllib3\n",
    "import requests\n",
    "\n",
    "# kleineres Modell 'esm2_t6_8M_UR50D' zum testen \n",
    "# verwendet 36-layer Transformer trained on UniParc\" (ca. 670 Mio. Parameter ) im Paper.\n",
    "model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    print(\"Modell auf GPU geladen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f2009d",
   "metadata": {},
   "source": [
    "### Hypothesis 1:\n",
    "final hidden representations of a sequence encode information about the family it belongs to.\n",
    "\n",
    "### Method:\n",
    "\n",
    "- Get Dataset (Pfam)\n",
    "- compare the distribution of cosine similarities of representations between pairs of residues that are aligned in the familyâ€™s MSA background distribution of cosine similarities between unaligned pairs of residues.\n",
    "- Compare with distributions befor learning (We need the embeddings befor pretraining (randomize model))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsupervised-learning-in-biology (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
