{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e6394d",
   "metadata": {},
   "source": [
    "# Learning Encodes Remote Homology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e91d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to import modules from helpers\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "# Gehe einen Ordner nach oben\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f5a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "from helpers import helper\n",
    "import time\n",
    "import io\n",
    "import urllib3\n",
    "import requests\n",
    "\n",
    "# kleineres Modell 'esm2_t6_8M_UR50D' zum testen \n",
    "# verwendet 36-layer Transformer trained on UniParc\" (ca. 670 Mio. Parameter ) im Paper.\n",
    "model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    print(\"Modell auf GPU geladen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f2009d",
   "metadata": {},
   "source": [
    "If structural homology is encoded in the metric structure of the representation space, then the distance between proteins reflects their degree of structural relatedness\n",
    "\n",
    "### Hypothesis 1:\n",
    "proteins of same superfamily are closer in the representation space then to proteins of other superfamilies.\n",
    "\n",
    "### Hypothesis 2:\n",
    "proteins that have the same fold even if they are of different superfamilies are closer to each other in the representation space than proteins of different superfamilies which dont have the fold. \n",
    "\n",
    "### Method:\n",
    "\n",
    "- Get Dataset\n",
    "- Test Hypothesis 1\n",
    "- Test Hypothesis 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6797d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SCOPe data from https://scop.berkeley.edu/downloads/scopeseq-2.07/dir.cla.scope.2.07-stable.txt...\n",
      "Total domains loaded: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sccs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Create a boolean mask\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m mask_excluded = \u001b[43mdf_scope\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msccs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.apply(is_excluded)\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Split datasets\u001b[39;00m\n\u001b[32m     71\u001b[39m df_excluded_structures = df_scope[mask_excluded]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/pandas/core/indexes/range.py:417\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    418\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'sccs'"
     ]
    }
   ],
   "source": [
    "# 1. SETUP: IGNORE SSL ERRORS\n",
    "# We suppress the warning that appears when verifying is disabled\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# 2. DOWNLOAD/LOAD SCOPe DATA\n",
    "# Using the latest stable version (2.07)\n",
    "url = \"https://scop.berkeley.edu/downloads/scopeseq-2.07/dir.cla.scope.2.07-stable.txt\"\n",
    "\n",
    "print(f\"Downloading SCOPe data from {url}...\")\n",
    "\n",
    "# FIX: Added verify=False to bypass the certificate error\n",
    "response = requests.get(url, verify=False)\n",
    "\n",
    "# The file has a header, we skip the first few lines that start with '#'\n",
    "content = response.content.decode('utf-8')\n",
    "data_lines = [line for line in content.split('\\n') if not line.startswith('#') and line.strip()]\n",
    "\n",
    "# Parse into DataFrame\n",
    "# SCOPe format usually: FA-DOMID  PDB  CHAIN  SCCS  SID\n",
    "data = []\n",
    "for line in data_lines:\n",
    "    parts = line.split('\\t')\n",
    "    if len(parts) >= 5:\n",
    "        data.append({\n",
    "            'domain_id': parts[0],\n",
    "            'pdb_id': parts[1],\n",
    "            'chain': parts[2],\n",
    "            'sccs': parts[3], # Structural Classification Code (e.g., b.1.1.1)\n",
    "            'sid': parts[4]\n",
    "        })\n",
    "\n",
    "df_scope = pd.DataFrame(data)\n",
    "print(f\"Total domains loaded: {len(df_scope)}\")\n",
    "\n",
    "# 3. DEFINE EXCLUSION CRITERIA\n",
    "# [cite_start]Based on the paper[cite: 205]:\n",
    "# \"exclude Rossmann-like folds (c.2 to c.5, c.27 and 28, c.30 and 31)\"\n",
    "# \"four- to eight-bladed β-propellers (b.66 to b.70)\"\n",
    "\n",
    "rossmann_exclusions = [\n",
    "    'c.2', 'c.3', 'c.4', 'c.5', \n",
    "    'c.27', 'c.28', \n",
    "    'c.30', 'c.31'\n",
    "]\n",
    "\n",
    "propeller_exclusions = [\n",
    "    'b.66', 'b.67', 'b.68', 'b.69', 'b.70'\n",
    "]\n",
    "\n",
    "# Combine all excluded folds\n",
    "excluded_folds = set(rossmann_exclusions + propeller_exclusions)\n",
    "\n",
    "# 4. APPLY FILTERING\n",
    "def is_excluded(sccs):\n",
    "    \"\"\"\n",
    "    Parses the SCCS code (e.g., 'c.2.1.1') and checks if the fold (e.g., 'c.2')\n",
    "    is in the exclusion list.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = sccs.split('.')\n",
    "        # Fold is the first two parts (Class.Fold)\n",
    "        fold_code = f\"{parts[0]}.{parts[1]}\"\n",
    "        return fold_code in excluded_folds\n",
    "    except IndexError:\n",
    "        return False\n",
    "\n",
    "# Create a boolean mask\n",
    "mask_excluded = df_scope['sccs'].apply(is_excluded)\n",
    "\n",
    "# Split datasets\n",
    "df_excluded_structures = df_scope[mask_excluded]\n",
    "df_clean_dataset = df_scope[~mask_excluded].copy()\n",
    "\n",
    "# 5. REPORT RESULTS\n",
    "print(\"-\" * 40)\n",
    "print(f\"Filtering Report:\")\n",
    "print(f\"Original Count:   {len(df_scope)}\")\n",
    "print(f\"Excluded Count:   {len(df_excluded_structures)}\")\n",
    "print(f\"Final Dataset:    {len(df_clean_dataset)}\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Exclusion Breakdown:\")\n",
    "print(f\"Rossmann-like excluded: {df_excluded_structures['sccs'].apply(lambda x: x.startswith('c')).sum()}\")\n",
    "print(f\"Beta-propellers excluded: {df_excluded_structures['sccs'].apply(lambda x: x.startswith('b')).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e52f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berechne TRAINIERTE Embeddings...\n"
     ]
    }
   ],
   "source": [
    "# 1. Embeddings mit dem TRAINIERTEN Modell holen\n",
    "print(\"Berechne TRAINIERTE Embeddings...\")\n",
    "# Schritt 1: Hidden Representations holen\n",
    "token_reps_trained, batch_strs_trained = helper.get_hidden_representations(model, alphabet, labels, seqs)\n",
    "# Schritt 2: Mean Pooling durchführen\n",
    "emb_trained = helper.get_protein_embedding(token_reps_trained, batch_strs_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f9aa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berechne UNTRAINIERTE Embeddings...\n"
     ]
    }
   ],
   "source": [
    "# 2. Embeddings mit einem zufälligen (UNTRAINIERTEN) Modell holen (natürlich ist hier ein Problem, \n",
    "# dass wir den seed nicht kennen alleine deshalb werden sich hier Sachen vom original Paper unterscheiden)\n",
    "print(\"Berechne UNTRAINIERTE Embeddings...\")\n",
    "untrained_model = helper.randomize_model(model)\n",
    "if torch.cuda.is_available(): \n",
    "    untrained_model = untrained_model.cuda()\n",
    "\n",
    "# Schritt 1: Hidden Representations holen (mit untrainiertem Modell)\n",
    "token_reps_untrained, batch_strs_untrained = helper.get_hidden_representations(untrained_model, alphabet, labels, seqs)\n",
    "# Schritt 2: Mean Pooling durchführen\n",
    "emb_untrained = helper.get_protein_embedding(token_reps_untrained, batch_strs_untrained)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsupervised-learning-in-biology (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
