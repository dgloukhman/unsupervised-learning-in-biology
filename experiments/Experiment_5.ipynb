{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e6394d",
   "metadata": {},
   "source": [
    "# Linear Model for structure prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84674467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import esm\n",
    "from esm.data import ESMStructuralSplitDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "# Gehe einen Ordner nach oben\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from helpers import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0880719",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438476c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 4 \n",
    "LR = 1e-4\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5239ffcb",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c6f6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProteinBertModel(\n",
       "  (embed_tokens): Embedding(35, 768, padding_idx=1)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): ESM1LayerNorm()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): ESM1LayerNorm()\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=72, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (embed_positions): SinusoidalPositionalEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this Block to load the pretrained model\n",
    "model, alphabet = esm.pretrained.esm1_t6_43M_UR50S()\n",
    "model = model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a586dbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProteinBertModel(\n",
       "  (embed_tokens): Embedding(35, 768, padding_idx=1)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): ESM1LayerNorm()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): ESM1LayerNorm()\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=72, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (embed_positions): SinusoidalPositionalEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this Block to load the randomized model\n",
    "untrained_model = helper.randomize_model(model)\n",
    "model = model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca82411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = model.args.embed_dim   \n",
    "LAYER_IDX = model.num_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81676afc",
   "metadata": {},
   "source": [
    "Define stuff we need later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f2009d",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "\n",
    "One of the oldest assumptions of sequencing biology: The underlying structure of a protein is a hidden variable that influences the patterns observed in sequence data. And vice versa the patterns observed in the sequence data influence the dtructure of a protein.\n",
    "In short: Structural information is encoded in the sequences.\n",
    "\n",
    "- secondary structure decides local choice and order of sequences\n",
    "- tertiary decides over long range choice and order of sequences\n",
    "\n",
    "Underlying general Hypothesis: Since 3d struture is encoded in the sequences. It is a logical hypothesis that via unsupervised learning the model learns to decode the hidden information about the secondary and tertiary strucure of the protein implicitly. \n",
    "\n",
    "In the paper they start by using simple linear models on top of the learned respresentations to see whether or not even simple models can infer about structure using the learned representations. If they are able to do that that would be very impressive.\n",
    "\n",
    "enabling a direct inspection of the structural content of representations.\n",
    "\n",
    "By comparing representations of the Transformer before and after pretraining, we can identify the information that emerges as a result of the unsupervised learning\n",
    "\n",
    "fivefold cross validation experiment to study generalization of structural information at the family, superfamily, and fold level.\n",
    "-\tFor each of the three levels, we construct a dataset of 15,297 protein structures using the SCOPe database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f45c27",
   "metadata": {},
   "source": [
    "# Hypothesis 1: Linear Logistic Regression for secondary structure prediction\n",
    "Via fivefold cross validation experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaf3caa",
   "metadata": {},
   "source": [
    "### Define the DSSP Mapping which Encodes the Secondary structures as indexes such that we can do logistic regression\n",
    "\n",
    "Welches DSSP mapping wird verwendet?\n",
    "\n",
    "- H: α-Helix (Alpha helix) \n",
    "- E: Extended Strand (Participates in a β-ladder/sheet) \n",
    "- T: Turn (Hydrogen-bonded turn) \n",
    "- S: Bend \n",
    "- G: 310​-Helix (Three-ten helix) \n",
    "- B: β-Bridge (Residue in an isolated β-bridge) \n",
    "- I: π-Helix (Pi helix) \n",
    "- C or -: Coil (Irregular/Loop/None)\n",
    "- P: theta-Helix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d759a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS8_MAPPING = {\n",
    "    'H': 0, 'E': 1, 'T': 2, 'S': 3, \n",
    "    'G': 4, 'B': 5, 'I': 6, '-': 7, 'C': 7 #, 'P': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39fc239",
   "metadata": {},
   "source": [
    "### Define the hat model which will be put on the embeddings \n",
    "\n",
    "This will must be trained with CrossEntropy then its equivalent to Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "938be8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProbeSSP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=8):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.proj(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dffe454",
   "metadata": {},
   "source": [
    "Fun fact the collate_fn function is a bridge between the batch represented as a List of tupels bridging to a batch representation as one X y matrix, so it generates these matrices resolving issue like varying len(x1) =/= len(x2) for out model to handle [(x1,y1), (x2,y2), ...] -> X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a865326",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProbeCollator:\n",
    "    def __init__(self, alphabet):\n",
    "        self.alphabet = alphabet\n",
    "        self.batch_converter = alphabet.get_batch_converter()\n",
    "        self.ss8_mapping = {\n",
    "            'H': 0, 'E': 1, 'T': 2, 'S': 3, \n",
    "            'G': 4, 'B': 5, 'I': 6, '-': 7, 'C': 7\n",
    "        }\n",
    "        self.ignore_index = -100\n",
    "\n",
    "    def _encode_ssp(self, ssp_str, max_len):\n",
    "        # Map string to indices\n",
    "        indices = [self.ss8_mapping.get(c, 7) for c in ssp_str]\n",
    "        \n",
    "        # Wrap with ignore_index for <cls> and <eos> tokens\n",
    "        # The ESM model input is: [<cls>, seq..., <eos>, <pad>...]\n",
    "        padded_labels = [self.ignore_index] + indices + [self.ignore_index]\n",
    "        \n",
    "        # --- ROBUSTNESS FIX ---\n",
    "        # 1. Truncate if the label is longer than the batch's max_len\n",
    "        #    (Handles cases where batch_converter truncated the sequence)\n",
    "        if len(padded_labels) > max_len:\n",
    "            padded_labels = padded_labels[:max_len]\n",
    "        \n",
    "        # 2. Pad if the label is shorter than the batch's max_len\n",
    "        padding_needed = max_len - len(padded_labels)\n",
    "        if padding_needed > 0:\n",
    "            padded_labels.extend([self.ignore_index] * padding_needed)\n",
    "            \n",
    "        return torch.tensor(padded_labels, dtype=torch.long)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # Filter None\n",
    "        batch = [item for item in batch if item is not None]\n",
    "        \n",
    "        # 1. Prepare inputs for ESM converter: List of (id, seq_string)\n",
    "        raw_inputs = [(str(i), item['seq']) for i, item in enumerate(batch)]\n",
    "        \n",
    "        # 2. Convert inputs: returns labels, sequences, and the PADDED tokens tensor\n",
    "        _, _, tokens = self.batch_converter(raw_inputs)\n",
    "        \n",
    "        # 3. Prepare targets\n",
    "        # We MUST use the tokens size as the ground truth for dimensions\n",
    "        max_len = tokens.size(1) \n",
    "        target_labels = []\n",
    "        \n",
    "        for item in batch:\n",
    "            # Get label string\n",
    "            ssp_str = item.get('ssp') \n",
    "            if ssp_str is None: ssp_str = item.get('label')\n",
    "            \n",
    "            # Encode with strict length enforcement\n",
    "            target_labels.append(self._encode_ssp(ssp_str, max_len))\n",
    "            \n",
    "        return {\n",
    "            'input_ids': tokens,\n",
    "            'labels': torch.stack(target_labels)\n",
    "        }\n",
    "\n",
    "# Re-instantiate the collator with the fix\n",
    "collator = LinearProbeCollator(alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f1a9c0",
   "metadata": {},
   "source": [
    "# Train Loop for every split level for 5 folds (Will train 15 models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee5efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Starting Split Level: superfamily\n",
      "====================\n",
      "  > Fold 0...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# --- TRAIN ---\u001b[39;00m\n\u001b[32m     56\u001b[39m     probe.train()\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m    Epoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m Train\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/esm/data.py:492\u001b[39m, in \u001b[36mESMStructuralSplitDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    490\u001b[39m pkl_fname = os.path.join(\u001b[38;5;28mself\u001b[39m.pkl_dir, name[\u001b[32m1\u001b[39m:\u001b[32m3\u001b[39m], \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pkl_fname, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     obj = \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Dict to store results\n",
    "final_results = {level: [] for level in ['superfamily']}# , 'family', 'fold']}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "for split_level in ['superfamily', 'family', 'fold']:\n",
    "    print(f\"\\n{'='*20}\\nStarting Split Level: {split_level}\\n{'='*20}\")\n",
    "    \n",
    "    # List to track accuracies for this specific split level (for the current loop)\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for fold in ['0']: #, '1', '2', '3', '4']:\n",
    "        print(f\"  > Fold {fold}...\")\n",
    "\n",
    "        # 1. Prepare Datasets\n",
    "        train_ds = ESMStructuralSplitDataset(\n",
    "            split_level=split_level, \n",
    "            cv_partition=fold, \n",
    "            split='train', \n",
    "            root_path='./data',\n",
    "            download=True\n",
    "        )\n",
    "\n",
    "        valid_ds = ESMStructuralSplitDataset(\n",
    "            split_level=split_level, \n",
    "            cv_partition=fold, \n",
    "            split='valid', \n",
    "            root_path='./data',\n",
    "            download=True\n",
    "        )\n",
    "\n",
    "        # 2. Prepare DataLoaders\n",
    "        train_loader = DataLoader(\n",
    "            train_ds, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=True, \n",
    "            collate_fn=collator,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        valid_loader = DataLoader(\n",
    "            valid_ds, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=False, \n",
    "            collate_fn=collator,\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        # 3. Initialize model\n",
    "        probe = LinearProbeSSP(input_dim=EMBED_DIM).to(DEVICE)\n",
    "        optimizer = optim.Adam(probe.parameters(), lr=LR)\n",
    "\n",
    "        # 4. Training Loop\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            # --- TRAIN ---\n",
    "            probe.train()\n",
    "            for batch in tqdm(train_loader, desc=f\"    Epoch {epoch+1} Train\", leave=False):\n",
    "                if batch is None: continue\n",
    "                \n",
    "                tokens = batch['input_ids'].to(DEVICE)\n",
    "                labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "                print(tokens.shape, labels.shape)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    results = model(tokens, repr_layers=[LAYER_IDX], return_contacts=False)\n",
    "                token_embeddings = results[\"representations\"][LAYER_IDX]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                logits = probe(token_embeddings)\n",
    "                loss = criterion(logits.view(-1, 8), labels.view(-1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # --- VALIDATION (After final epoch) ---\n",
    "        # We collect ALL targets and preds to use your specific snippet\n",
    "        probe.eval()\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(valid_loader, desc=f\"    Validating Fold {fold}\", leave=False):\n",
    "                if batch is None: continue\n",
    "\n",
    "                tokens = batch['input_ids'].to(DEVICE)\n",
    "                labels = batch['labels'].to(DEVICE)\n",
    "                \n",
    "                results = model(tokens, repr_layers=[LAYER_IDX], return_contacts=False)\n",
    "                token_embeddings = results[\"representations\"][LAYER_IDX]\n",
    "                \n",
    "                logits = probe(token_embeddings)\n",
    "                \n",
    "                # Get predictions\n",
    "                batch_preds = torch.argmax(logits, dim=-1)\n",
    "                \n",
    "                # --- MASKING ---\n",
    "                # We must filter out the padding/-100 tokens to get valid accuracy\n",
    "                mask = (labels != -100)\n",
    "                \n",
    "                # Extract only valid positions and move to CPU numpy\n",
    "                valid_preds = batch_preds[mask].cpu().numpy()\n",
    "                valid_labels = labels[mask].cpu().numpy()\n",
    "                \n",
    "                all_preds.extend(valid_preds)\n",
    "                all_targets.extend(valid_labels)\n",
    "\n",
    "        # --- YOUR SNIPPET ---\n",
    "        # Calculate Q8 Accuracy for this fold\n",
    "        acc = accuracy_score(all_targets, all_preds)\n",
    "        fold_accuracies.append(acc)\n",
    "        print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n",
    "        \n",
    "    # Store the results for this split level\n",
    "    final_results[split_level] = fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c89a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "labels = list(final_results.keys())\n",
    "data = list(final_results.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create boxplot\n",
    "# patch_artist=True allows us to color the boxes\n",
    "bplot = plt.boxplot(data, \n",
    "                    tick_labels=labels, \n",
    "                    patch_artist=True,\n",
    "                    medianprops=dict(color=\"black\", linewidth=1.5))\n",
    "\n",
    "# Styling\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "for patch, color in zip(bplot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Add jittered scatter points to show individual fold performance\n",
    "for i, accs in enumerate(data):\n",
    "    x = np.random.normal(i + 1, 0.04, size=len(accs)) # Add small jitter to x-axis\n",
    "    plt.plot(x, accs, 'r.', alpha=0.6)\n",
    "\n",
    "plt.title('ESM Linear Probe Q8 Accuracy by Split Level')\n",
    "plt.ylabel('Q8 Accuracy')\n",
    "plt.xlabel('Structural Split Level')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.ylim(0, 1.0) # Set reasonable y-limits (0 to 100%)\n",
    "\n",
    "# Print statistics table\n",
    "print(f\"{'Split Level':<15} | {'Mean Acc':<10} | {'Std Dev':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for level, accs in final_results.items():\n",
    "    print(f\"{level:<15} | {np.mean(accs):.4f}     | {np.std(accs):.4f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb2a4a",
   "metadata": {},
   "source": [
    "# Hypothesis 2: Linear Binary Map prediction for contact point prediction\n",
    "Via fivefold cross validation experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13213861",
   "metadata": {},
   "source": [
    "### Define the hat model which will be put on the embeddings \n",
    "\n",
    "Two seperate linear Projections which are combined via dot product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e1d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearContactProbe(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the linear contact probe described in Rives et al. (ESM-1b paper).\n",
    "    Uses TWO SEPARATE linear projections (W1, W2) and computes their dot product.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, projection_dim=128):\n",
    "        super().__init__()\n",
    "        # The paper specifies \"two separate linear projections\"\n",
    "        self.proj1 = nn.Linear(input_dim, projection_dim)\n",
    "        self.proj2 = nn.Linear(input_dim, projection_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [Batch, SeqLen, EmbedDim]\n",
    "        \n",
    "        # Project separately\n",
    "        z1 = self.proj1(x) # [Batch, SeqLen, ProjDim]\n",
    "        z2 = self.proj2(x) # [Batch, SeqLen, ProjDim]\n",
    "        \n",
    "        # Compute Dot Product: z1 * z2^T\n",
    "        # Shape: [Batch, SeqLen, SeqLen]\n",
    "        logits = torch.bmm(z1, z2.transpose(1, 2))\n",
    "        \n",
    "        # Symmetrize the output\n",
    "        # Physical contacts are symmetric (C_ij = C_ji). \n",
    "        # Although the projections are separate, we enforce symmetry on the prediction.\n",
    "        logits = (logits + logits.transpose(1, 2)) / 2\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919c9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- COLLATOR ---\n",
    "class ContactProbeCollator:\n",
    "    def __init__(self, alphabet):\n",
    "        self.alphabet = alphabet\n",
    "        self.batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        batch = [item for item in batch if item is not None]\n",
    "        \n",
    "        # 1. Inputs\n",
    "        raw_inputs = [(str(i), item['seq']) for i, item in enumerate(batch)]\n",
    "        _, _, tokens = self.batch_converter(raw_inputs)\n",
    "        \n",
    "        # 2. Contact Maps\n",
    "        max_len = tokens.size(1)\n",
    "        batch_contacts = []\n",
    "        \n",
    "        for item in batch:\n",
    "            seq_len = len(item['seq'])\n",
    "            dist_map = item['dist'] # Shape (L, L)\n",
    "            \n",
    "            # Contact definition: distance < 8.0 Angstroms\n",
    "            contacts = (dist_map < 8.0).astype(np.float32)\n",
    "            \n",
    "            # Pad to [max_len, max_len]\n",
    "            padded_contacts = np.full((max_len, max_len), -1.0, dtype=np.float32)\n",
    "            # Offset by 1 for <cls>\n",
    "            padded_contacts[1:seq_len+1, 1:seq_len+1] = contacts\n",
    "            \n",
    "            batch_contacts.append(torch.from_numpy(padded_contacts))\n",
    "            \n",
    "        return {\n",
    "            'input_ids': tokens,\n",
    "            'contacts': torch.stack(batch_contacts)\n",
    "        }\n",
    "\n",
    "contact_collator = ContactProbeCollator(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec10231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_at_l(logits, labels, seq_len):\n",
    "    \"\"\"\n",
    "    Computes Precision of Top-L predictions for long-range contacts (|i-j| >= 24).\n",
    "    \"\"\"\n",
    "    # Exclude special tokens\n",
    "    valid_logits = logits[1:seq_len+1, 1:seq_len+1]\n",
    "    valid_labels = labels[1:seq_len+1, 1:seq_len+1]\n",
    "    \n",
    "    # Mask for long-range contacts\n",
    "    l = valid_logits.shape[0]\n",
    "    idx = torch.arange(l, device=logits.device)\n",
    "    i, j = torch.meshgrid(idx, idx, indexing='ij')\n",
    "    mask = torch.abs(i - j) >= 24\n",
    "    \n",
    "    masked_logits = valid_logits[mask]\n",
    "    masked_labels = valid_labels[mask]\n",
    "    \n",
    "    if masked_labels.numel() == 0: return 0.0\n",
    "    \n",
    "    # Top-L (where L is sequence length)\n",
    "    k = min(l, masked_logits.numel())\n",
    "    if k == 0: return 0.0\n",
    "\n",
    "    _, top_indices = torch.topk(masked_logits, k)\n",
    "    top_labels = masked_labels[top_indices]\n",
    "    \n",
    "    return (top_labels.sum() / k).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e5a460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Starting Contact Split Level: superfamily\n",
      "====================\n",
      "  > Fold 0...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Epoch 1 Train:   0%|          | 0/3008 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m contacts = batch[\u001b[33m'\u001b[39m\u001b[33mcontacts\u001b[39m\u001b[33m'\u001b[39m].to(DEVICE)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     results = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepr_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLAYER_IDX\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_contacts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m token_embeddings = results[\u001b[33m\"\u001b[39m\u001b[33mrepresentations\u001b[39m\u001b[33m\"\u001b[39m][LAYER_IDX]\n\u001b[32m     36\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/esm/model/esm1.py:156\u001b[39m, in \u001b[36mProteinBertModel.forward\u001b[39m\u001b[34m(self, tokens, repr_layers, need_head_weights, return_contacts)\u001b[39m\n\u001b[32m    153\u001b[39m     padding_mask = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers):\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     x, attn = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_attn_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_head_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_head_weights\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (layer_idx + \u001b[32m1\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m repr_layers:\n\u001b[32m    160\u001b[39m         hidden_representations[layer_idx + \u001b[32m1\u001b[39m] = x.transpose(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/esm/modules.py:139\u001b[39m, in \u001b[36mTransformerLayer.forward\u001b[39m\u001b[34m(self, x, self_attn_mask, self_attn_padding_mask, need_head_weights)\u001b[39m\n\u001b[32m    137\u001b[39m x = \u001b[38;5;28mself\u001b[39m.final_layer_norm(x)\n\u001b[32m    138\u001b[39m x = gelu(\u001b[38;5;28mself\u001b[39m.fc1(x))\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m x = residual + x\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x, attn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-learning-in-biology/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "contact_results = {level: [] for level in ['superfamily']}# , 'family', 'fold']}\n",
    "contact_criterion = nn.BCEWithLogitsLoss(reduction='none') \n",
    "\n",
    "for split_level in ['superfamily', 'family', 'fold']:\n",
    "    print(f\"\\n{'='*20}\\nStarting Contact Split Level: {split_level}\\n{'='*20}\")\n",
    "    \n",
    "    fold_precisions = []\n",
    "    \n",
    "    for fold in ['0']:# , '1', '2', '3', '4']:\n",
    "        print(f\"  > Fold {fold}...\")\n",
    "\n",
    "        # 1. Dataset\n",
    "        train_ds = ESMStructuralSplitDataset(split_level=split_level, cv_partition=fold, split='train', root_path='./data', download=True)\n",
    "        valid_ds = ESMStructuralSplitDataset(split_level=split_level, cv_partition=fold, split='valid', root_path='./data', download=True)\n",
    "        \n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=contact_collator, num_workers=0)\n",
    "        valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=contact_collator, num_workers=0)\n",
    "\n",
    "        # 2. Model\n",
    "        probe = LinearContactProbe(input_dim=EMBED_DIM, projection_dim=128).to(DEVICE)\n",
    "        optimizer = optim.Adam(probe.parameters(), lr=LR)\n",
    "\n",
    "        # 3. Train\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            probe.train()\n",
    "            for batch in tqdm(train_loader, desc=f\"    Epoch {epoch+1} Train\", leave=False):\n",
    "                if batch is None: continue\n",
    "                \n",
    "                tokens = batch['input_ids'].to(DEVICE)\n",
    "                contacts = batch['contacts'].to(DEVICE)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    results = model(tokens, repr_layers=[LAYER_IDX], return_contacts=False)\n",
    "                token_embeddings = results[\"representations\"][LAYER_IDX]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                logits = probe(token_embeddings)\n",
    "                \n",
    "                loss_mask = (contacts != -1)\n",
    "                loss = contact_criterion(logits, contacts)\n",
    "                \n",
    "                if loss_mask.sum() > 0:\n",
    "                    masked_loss = loss[loss_mask].mean()\n",
    "                    masked_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "        # 4. Validate\n",
    "        probe.eval()\n",
    "        precisions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(valid_loader, desc=f\"    Validating Fold {fold}\", leave=False):\n",
    "                if batch is None: continue\n",
    "                tokens = batch['input_ids'].to(DEVICE)\n",
    "                contacts = batch['contacts'].to(DEVICE)\n",
    "                \n",
    "                results = model(tokens, repr_layers=[LAYER_IDX], return_contacts=False)\n",
    "                token_embeddings = results[\"representations\"][LAYER_IDX]\n",
    "                \n",
    "                logits = probe(token_embeddings)\n",
    "                \n",
    "                for i in range(tokens.size(0)):\n",
    "                    # Determine seq length (tokens != pad(1)) - 2 (cls, eos)\n",
    "                    seq_len = (tokens[i] != 1).sum().item() - 2\n",
    "                    p = compute_precision_at_l(logits[i], contacts[i], seq_len)\n",
    "                    precisions.append(p)\n",
    "\n",
    "        avg_p = np.mean(precisions)\n",
    "        fold_precisions.append(avg_p)\n",
    "        print(f\"Fold {fold} Top-L Precision: {avg_p:.4f}\")\n",
    "\n",
    "    contact_results[split_level] = fold_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ae251",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(contact_results.keys())\n",
    "data = list(contact_results.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bplot = plt.boxplot(data, tick_labels=labels, patch_artist=True, medianprops=dict(color=\"black\"))\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "for patch, color in zip(bplot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "for i, accs in enumerate(data):\n",
    "    x = np.random.normal(i + 1, 0.04, size=len(accs))\n",
    "    plt.plot(x, accs, 'r.', alpha=0.6)\n",
    "\n",
    "plt.title('ESM Linear Contact Top-L Precision by Split Level')\n",
    "plt.ylabel('Top-L Long-Range Precision')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()\n",
    "\n",
    "print(f\"{'Split Level':<15} | {'Mean Prec':<10} | {'Std Dev':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for level, accs in contact_results.items():\n",
    "    print(f\"{level:<15} | {np.mean(accs):.4f}     | {np.std(accs):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsupervised-learning-in-biology (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
