{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e6394d",
   "metadata": {},
   "source": [
    "# Learning Encodes Alignment within a Protein Family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e91d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to import modules from helpers\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "# Gehe einen Ordner nach oben\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f5a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "from helpers import helper\n",
    "import time\n",
    "import io\n",
    "import urllib3\n",
    "import requests\n",
    "\n",
    "# kleineres Modell 'esm2_t6_8M_UR50D' zum testen \n",
    "# verwendet 36-layer Transformer trained on UniParc\" (ca. 670 Mio. Parameter ) im Paper.\n",
    "model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    print(\"Modell auf GPU geladen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f2009d",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "\n",
    "One of the oldest assumptions of sequencing biology: The underlying structure of a protein is a hidden variable that influences the patterns observed in sequence data. And vice versa the patterns observed in the sequence data influence the dtructure of a protein.\n",
    "In short: Structural information is encoded in the sequences.\n",
    "\n",
    "- secondary structure decides local choice and order of sequences\n",
    "- tertiary decides over long range choice and order of sequences\n",
    "\n",
    "Underlying general Hypothesis: Since 3d struture is encoded in the sequences. It is a logical hypothesis that via unsupervised learning the model learns to decode the hidden information about the secondary and tertiary strucure of the protein implicitly. \n",
    "\n",
    "In the paper they start by using simple linear models on top of the learned respresentations to see whether or not even simple models can infer about structure using the learned representations. If they are able to do that that would be very impressive.\n",
    "\n",
    "enabling a direct inspection of the structural content of representations.\n",
    "\n",
    "By comparing representations of the Transformer before and after pretraining, we can identify the information that emerges as a result of the unsupervised learning\n",
    "\n",
    "fivefold cross validation experiment to study generalization of structural information at the family, superfamily, and fold level.\n",
    "-\tFor each of the three levels, we construct a dataset of 15,297 protein structures using the SCOPe database.\n",
    "\n",
    "### Hypothesis 1:\n",
    "\n",
    "\n",
    "### Hypothesis 2:\n",
    "final hidden representations of a sequence encode information about the family it belongs to.\n",
    "\n",
    "### Method:\n",
    "\n",
    "- Get Dataset (Pfam)\n",
    "- compare the distribution of cosine similarities of representations between pairs of residues that are aligned in the familyâ€™s MSA background distribution of cosine similarities between unaligned pairs of residues.\n",
    "- Compare with distributions befor learning (We need the embeddings befor pretraining (randomize model))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsupervised-learning-in-biology (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
